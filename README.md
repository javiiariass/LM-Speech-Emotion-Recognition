# Sistema de DetecciÃ³n de Emociones en Audio (SER) ğŸ™ï¸ğŸ¤–

Este repositorio aloja la documentaciÃ³n y el cÃ³digo fuente de la **PrÃ¡ctica 3: DetecciÃ³n de Emociones mediante CaracterÃ­sticas AcÃºsticas del Habla** para la asignatura de Procesamiento del Habla.

El objetivo principal es desarrollar un sistema capaz de clasificar el estado emocional de un hablante basÃ¡ndose exclusivamente en la **fÃ­sica del sonido** (intensidad, tono, MFCCs), sin utilizar transcripciÃ³n de texto (ASR) ni procesamiento de lenguaje natural (NLP).

> [!important]
> DocumentaciÃ³n: ver [aquÃ­](docs/Documentacion.md)

***

## ğŸ“‚ Estructura del Repositorio

```text
LM-Speech-Emotion-Recognition/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/             # CSVs con caracterÃ­sticas extraÃ­das (MFCCs)
â”‚   â”‚   â”œâ”€â”€ ssi_custom_features.xlsx  # Dataset de Entrenamiento (Source)
â”‚   â”‚   â”œâ”€â”€ testing_ravdess.csv      # Dataset de Control (RAVDESS)
â”‚   â”‚   â””â”€â”€ real_tests.xlsx           # Dataset Experimental (Voces propias)
â”‚   â””â”€â”€ models/                 # modelos guardados de los flujos orange
â”œâ”€â”€ src/                       # CÃ³digo fuente Python
â”‚   â”œâ”€â”€ training_extractor/    # Extractor para el dataset principal
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚
â”‚   â””â”€â”€ Datasets_extractor.ipynb  # Cuaderno colab para crear los 3 datasets necesarios
â”‚
â”œâ”€â”€ orange_workflow/           # Flujos de Orange Data Mining (.ows)
â”‚   â”œâ”€â”€ Practica3_3_Emociones_Agrupadas.ows    # Estrategia de agrupaciÃ³n (3 emociones)
â”‚   â”œâ”€â”€ Practica3_4_Emociones.ows   # Estrategia de selecciÃ³n (4 emociones)
â”‚   â””â”€â”€ capturas/                        # Esquemas visuales del flujo
â”‚
â””â”€â”€ docs/                      # DocumentaciÃ³n adicional y enunciados
    â”œâ”€â”€ Documentacion.md       # DocumentaciÃ³n en formato Markdown
    â”œâ”€â”€ Documentacion.pdf         # DocumentaciÃ³n en pdf
    â””â”€â”€ assets/                 # Archivos de apoyo para documentaciÃ³n
```

***

## âš™ï¸ MetodologÃ­a y Flujo de Trabajo

El proyecto implementa un pipeline hÃ­brido que combina la extracciÃ³n de caracterÃ­sticas en Python con el modelado predictivo en Orange Data Mining.

### 1. ExtracciÃ³n de CaracterÃ­sticas (Python)
Utilizando la librerÃ­a `librosa`, transformamos los audios crudos (.wav) en vectores numÃ©ricos. La caracterÃ­stica mÃ¡s determinante seleccionada ha sido los **MFCCs (Mel-frequency cepstral coefficients)**, calculando la media de 40 coeficientes por audio.

### 2. Estrategia de ValidaciÃ³n (Orange Data Mining)
A diferencia de los enfoques tradicionales, hemos diseÃ±ado una validaciÃ³n en dos niveles para medir tanto la robustez estadÃ­stica como la generalizaciÃ³n real (**Cross-Corpus Validation**).

#### A. ValidaciÃ³n Interna (Cross-Validation)
* **Objetivo:** Evitar el *sesgo de particiÃ³n* y el sobreajuste al dataset de entrenamiento.
* **MÃ©todo:** Utilizamos el widget *Test & Score* con **k-fold cross-validation** sobre el archivo `ssi_custom_features.csv`. Esto asegura que el modelo es estable matemÃ¡ticamente dentro del dominio de datos original.

#### B. ValidaciÃ³n Externa (Inferencia)
* **Objetivo:** Evaluar la capacidad del modelo para generalizar ante condiciones acÃºsticas desconocidas (Domain Shift).
* **MÃ©todo:** Utilizamos el widget *Predictions*. Entrenamos el modelo con la totalidad del dataset principal y lanzamos predicciones sobre dos fuentes externas:
    1.  **RAVDESS:** Dataset de actores profesionales (Audio limpio, actuaciÃ³n arquetÃ­pica).
    2.  **Voces Propias:** Grabaciones con equipo rudimentario (MicrÃ³fonos no profesionales, ruido ambiente) con el objetivo de validar el rendimiento ante la ausencia de acondicionamiento acÃºstico (ruido de fondo, eco y micrÃ³fonos estÃ¡ndar).

***

## ğŸ§ª ExperimentaciÃ³n

Se han diseÃ±ado dos flujos de trabajo en Orange (`.ows`) para probar distintas hipÃ³tesis de modelado:

| Experimento | Archivo `.ows` | DescripciÃ³n |
| :--- | :--- | :--- |
| **Estrategia de AgrupaciÃ³n** | `Practica_3.ows` | Se agrupan emociones semÃ¡nticamente cercanas en **3 macrounidades**. Busca maximizar el *Accuracy* global reduciendo la granularidad del problema. |
| **Estrategia de SelecciÃ³n** | `Practica_3_4Emociones.ows` | Se filtran y conservan Ãºnicamente las **4 emociones bÃ¡sicas** (Ira, Tristeza, Felicidad, Neutral). EvalÃºa el rendimiento en el esquema estÃ¡ndar de Paul Ekman. |

***

## ğŸ“Š DiscusiÃ³n de Resultados

Tras el anÃ¡lisis de las matrices de confusiÃ³n en ambas estrategias, hemos observado un fenÃ³meno notable:

### La Paradoja de RAVDESS
El modelo obtiene un rendimiento significativamente superior en el dataset externo **RAVDESS** (88-94% de acierto) comparado con el propio dataset de entrenamiento (~70%) o las voces propias.

**Conclusiones tÃ©cnicas:**
1.  **Arquetipos Emocionales:** El modelo ha aprendido eficazmente a detectar emociones "de caricatura" o de alta intensidad (propias de actores entrenados). Al ser RAVDESS un dataset de actuaciÃ³n extrema, las caracterÃ­sticas acÃºsticas son muy separables.
2.  **Gap de ProducciÃ³n:** El bajo rendimiento en las **voces propias** indica que el modelo es sensible a las condiciones del canal (micrÃ³fono, ruido) y a la falta de entrenamiento actoral de los sujetos de prueba.
3.  **No es Overfitting clÃ¡sico:** El hecho de que funcione bien en RAVDESS descarta un sobreajuste simple; el modelo *sabe* detectar emociones, pero requiere una limpieza de seÃ±al y una expresividad que no siempre se da en entornos naturales.

***

## ğŸ› ï¸ InstalaciÃ³n y Uso

### ObtenciÃ³n de datasets

Ejecutar scripts de python localmente o abrir el cuaderno de Google Colab

#### Local

1. **Requisitos de Python:**
   ```bash
   pip install librosa numpy pandas kagglehub
   ```

#### Google Colab


### **EjecuciÃ³n de Orange:**
   * Instalar [Orange Data Mining](https://orangedatamining.com/).
   * Abrir los archivos `.ows` situados en `orange_workflow/`.
   * **Importante:** Es posible que debas re-vincular la ruta de los archivos CSV en los widgets "File" al descargarlos en tu mÃ¡quina local.