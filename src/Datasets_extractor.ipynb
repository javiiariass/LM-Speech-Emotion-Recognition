{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instalacion dependencias"
      ],
      "metadata": {
        "id": "PdKZQdUCNouL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. INSTALACIÓN DE LIBRERÍAS ---\n",
        "# Instalamos kagglehub y aseguramos librosa\n",
        "!pip install -q kagglehub librosa numpy pandas datasets tqdm openpyxl soundfile"
      ],
      "metadata": {
        "id": "HJNzypKqNobb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset SSI Entrenamiento"
      ],
      "metadata": {
        "id": "hriftEZ8Nf60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def extract_features(audio_data, sample_rate, n_mfcc=40):\n",
        "    \"\"\"\n",
        "    Extrae un conjunto de características de una señal de audio.\n",
        "    Usamos la media de los MFCCs, Chroma y Mel Spectrogram.\n",
        "    \"\"\"\n",
        "    features = {}\n",
        "\n",
        "    # Asegurarse de que el audio sea flotante (requerido por librosa)\n",
        "    if audio_data.dtype != np.float32:\n",
        "        audio_data = audio_data.astype(np.float32)\n",
        "\n",
        "    # MFCCs (Coeficientes Cepstrales en la Frecuencia Mel)\n",
        "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc)\n",
        "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
        "\n",
        "    for i, mfcc_val in enumerate(mfccs_mean):\n",
        "        features[f'mfcc_{i+1}_mean'] = mfcc_val\n",
        "\n",
        "    # Chroma (Características de Tono)\n",
        "    chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate)\n",
        "    features['chroma_mean'] = np.mean(chroma)\n",
        "\n",
        "    # Mel Spectrogram (Espectrograma en escala Mel)\n",
        "    mel = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "    features['mel_mean'] = np.mean(mel)\n",
        "\n",
        "    # Contraste Espectral (Spectral Contrast)\n",
        "    contrast = librosa.feature.spectral_contrast(y=audio_data, sr=sample_rate)\n",
        "    features['contrast_mean'] = np.mean(contrast)\n",
        "\n",
        "    return features\n",
        "\n",
        "# --- Script Principal ---\n",
        "\n",
        "print(\"Iniciando el proceso...\")\n",
        "\n",
        "os.environ['TRANSFORMERS_TRUST_REMOTE_CODE'] = '1'\n",
        "os.environ['HF_DATASETS_DISABLE_TORCHCODEC'] = '1'\n",
        "\n",
        "dataset_name = \"stapesai/ssi-speech-emotion-recognition\"\n",
        "SAMPLING_RATE = 16000\n",
        "\n",
        "# 1. CARGAR DATOS - Sin Audio wrapper para evitar decodificación\n",
        "print(\"Cargando el dataset...\")\n",
        "try:\n",
        "    dataset = load_dataset(dataset_name, 'default', split='train')\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    dataset = load_dataset(dataset_name, split='train')\n",
        "\n",
        "print(f\"Dataset cargado. Total de muestras: {len(dataset)}\")\n",
        "\n",
        "# 2. EXTRAER CARACTERÍSTICAS\n",
        "processed_data = []\n",
        "print(\"Extrayendo características...\")\n",
        "\n",
        "# Acceder directamente a la tabla PyArrow para evitar decodificación\n",
        "arrow_table = dataset.data\n",
        "\n",
        "# Inspeccionar la estructura\n",
        "print(f\"Columnas disponibles: {arrow_table.column_names}\")\n",
        "\n",
        "# Procesar todas las muestras\n",
        "for idx in tqdm(range(arrow_table.num_rows)):\n",
        "    try:\n",
        "        # Acceder directamente a la tabla PyArrow sin formateo\n",
        "        row_dict = {\n",
        "            name: arrow_table.column(name)[idx].as_py()\n",
        "            for name in arrow_table.column_names\n",
        "        }\n",
        "\n",
        "        # Obtener info del audio y emoción\n",
        "        file_path_info = row_dict.get('file_path')  # Dict con 'bytes' y 'path'\n",
        "        emotion_label = row_dict.get('emotion')\n",
        "\n",
        "        # Extraer audio bytes\n",
        "        if isinstance(file_path_info, dict) and 'bytes' in file_path_info:\n",
        "            audio_bytes = file_path_info['bytes']\n",
        "\n",
        "            # Guardar temporalmente y cargar con librosa\n",
        "            import tempfile\n",
        "            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:\n",
        "                tmp.write(audio_bytes)\n",
        "                tmp_path = tmp.name\n",
        "            try:\n",
        "                audio_data, sample_rate = librosa.load(tmp_path, sr=SAMPLING_RATE)\n",
        "\n",
        "                # Extraer características\n",
        "                features = extract_features(audio_data, sample_rate)\n",
        "                features['emotion'] = emotion_label\n",
        "                processed_data.append(features)\n",
        "            finally:\n",
        "                os.remove(tmp_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        pass  # Ignorar errores\n",
        "\n",
        "print(f\"\\nSe procesaron {len(processed_data)} muestras\")\n",
        "\n",
        "# 3. CREAR Y GUARDAR EL CSV y XLSX\n",
        "if processed_data:\n",
        "    print(\"Creando DataFrame de Pandas...\")\n",
        "    df = pd.DataFrame(processed_data)\n",
        "\n",
        "    # Poner 'emotion' primero\n",
        "    cols = ['emotion'] + [col for col in df.columns if col != 'emotion']\n",
        "    df = df[cols]\n",
        "\n",
        "    # Guardar como CSV\n",
        "    csv_filename = 'ssi_custom_features.csv'\n",
        "    df.to_csv(csv_filename, index=False, sep=',', quoting=1)\n",
        "    print(f\"CSV guardado en: {csv_filename}\")\n",
        "\n",
        "    # Guardar como XLSX\n",
        "    xlsx_filename = 'ssi_custom_features.xlsx'\n",
        "    df.to_excel(xlsx_filename, index=False, sheet_name='Datos')\n",
        "\n",
        "    print(f\"\\n¡Proceso completado!\")\n",
        "    print(f\"XLSX guardado en: {xlsx_filename}\")\n",
        "    print(f\"Total de registros: {len(df)}\")\n",
        "    print(\"\\nVista previa de los datos:\")\n",
        "    print(df.head())\n",
        "    print(f\"\\nForma del dataset: {df.shape}\")\n",
        "    print(f\"Columnas: {list(df.columns[:10])}...\")  # Mostrar solo primeras 10\n",
        "else:\n",
        "    print(\"No se procesaron datos.\")"
      ],
      "metadata": {
        "id": "g5EBJlinNefN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset RAVDESS Tests"
      ],
      "metadata": {
        "id": "bTxEmVbDNVId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import kagglehub\n",
        "import os\n",
        "import glob\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 2. DESCARGA DEL DATASET ---\n",
        "print(\"Descargando RAVDESS con kagglehub...\")\n",
        "# Descargamos la última versión del dataset\n",
        "path_dataset = kagglehub.dataset_download(\"uwrfkaggler/ravdess-emotional-speech-audio\")\n",
        "\n",
        "print(f\"Dataset descargado en: {path_dataset}\")\n",
        "\n",
        "# --- 3. FUNCIÓN DE EXTRACCIÓN (Tu \"matemática\" original) ---\n",
        "def extract_features(audio_data, sample_rate, n_mfcc=40):\n",
        "    features = {}\n",
        "\n",
        "    if audio_data.dtype != np.float32:\n",
        "        audio_data = audio_data.astype(np.float32)\n",
        "\n",
        "    # MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc)\n",
        "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
        "    for i, mfcc_val in enumerate(mfccs_mean):\n",
        "        features[f'mfcc_{i+1}_mean'] = mfcc_val\n",
        "\n",
        "    # Chroma\n",
        "    chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate)\n",
        "    features['chroma_mean'] = np.mean(chroma)\n",
        "\n",
        "    # Mel Spectrogram\n",
        "    mel = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "    features['mel_mean'] = np.mean(mel)\n",
        "\n",
        "    # Spectral Contrast\n",
        "    contrast = librosa.feature.spectral_contrast(y=audio_data, sr=sample_rate)\n",
        "    features['contrast_mean'] = np.mean(contrast)\n",
        "\n",
        "    return features\n",
        "\n",
        "# --- 4. CONFIGURACIÓN ---\n",
        "# Mapa de emociones (Asegúrate que coincidan con las de tu modelo en Orange)\n",
        "emotion_map = {\n",
        "    '01': 'NEU',\n",
        "    '02': 'CAL',     # Si tu modelo no tiene CALM, coméntalo o cámbialo a NEUTRAL\n",
        "    '03': 'HAP',\n",
        "    '04': 'SAD',\n",
        "    '05': 'ANG',\n",
        "    '06': 'FEA',\n",
        "    '07': 'DIS',\n",
        "    '08': 'SUR'\n",
        "}\n",
        "\n",
        "processed_data = []\n",
        "processed_filenames = set() # Para evitar duplicados\n",
        "SAMPLE_RATE = 16000\n",
        "\n",
        "print(\"\\nIniciando procesamiento de audios...\")\n",
        "\n",
        "# --- 5. BUCLE PRINCIPAL ---\n",
        "# Usamos os.walk para recorrer la carpeta descargada por kagglehub\n",
        "for dirname, _, filenames in os.walk(path_dataset):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith('.wav'):\n",
        "\n",
        "            # FILTRO DE DUPLICADOS: Si ya vimos este nombre de archivo, lo saltamos\n",
        "            if filename in processed_filenames:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Formato RAVDESS: 03-01-06-01-01-01-01.wav (Emoción es el 3er número)\n",
        "                parts = filename.split('-')\n",
        "\n",
        "                if len(parts) >= 3 and parts[2] in emotion_map:\n",
        "\n",
        "                    # Marcamos como procesado\n",
        "                    processed_filenames.add(filename)\n",
        "\n",
        "                    emotion_code = parts[2]\n",
        "                    emotion_label = emotion_map[emotion_code]\n",
        "                    file_path = os.path.join(dirname, filename)\n",
        "\n",
        "                    # Cargar y extraer (usando sr=16000 para consistencia)\n",
        "                    audio_data, _ = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "                    features = extract_features(audio_data, SAMPLE_RATE)\n",
        "                    features['emotion'] = emotion_label\n",
        "\n",
        "                    processed_data.append(features)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error en {filename}: {e}\")\n",
        "                continue\n",
        "\n",
        "# --- 6. GUARDAR CSV ---\n",
        "if processed_data:\n",
        "    df = pd.DataFrame(processed_data)\n",
        "\n",
        "    # Ordenar columnas\n",
        "    cols = ['emotion'] + [col for col in df.columns if col != 'emotion']\n",
        "    df = df[cols]\n",
        "\n",
        "    output_filename = 'ravdess_test_colab.csv'\n",
        "    df.to_csv(output_filename, index=False)\n",
        "\n",
        "    print(f\"\\n¡Proceso completado!\")\n",
        "    print(f\"Archivos únicos procesados: {len(df)}\")\n",
        "    print(f\"Archivo guardado como: {output_filename}\")\n",
        "\n",
        "    # Código para descargar el archivo automáticamente a tu PC\n",
        "    from google.colab import files\n",
        "    files.download(output_filename)\n",
        "else:\n",
        "    print(\"No se encontraron datos para procesar.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "akiCRIGSqDFD",
        "outputId": "b7b08478-a827-47e1-f488-41b01cfeeeb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando RAVDESS con kagglehub...\n",
            "Using Colab cache for faster access to the 'ravdess-emotional-speech-audio' dataset.\n",
            "Dataset descargado en: /kaggle/input/ravdess-emotional-speech-audio\n",
            "\n",
            "Iniciando procesamiento de audios...\n",
            "\n",
            "¡Proceso completado!\n",
            "Archivos únicos procesados: 1440\n",
            "Archivo guardado como: ravdess_test_colab.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7f67479c-e6cb-4e78-a330-1c2b1b1898c5\", \"ravdess_test_colab.csv\", 664157)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset nuestros audios"
      ],
      "metadata": {
        "id": "98MtKputOv5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K409YIE-O0_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- CONFIGURACIÓN ---\n",
        "local_folder = \"/content/drive/MyDrive/Practica_3_PH_Emociones/mis_audios\"      # Nombre de tu carpeta\n",
        "SAMPLING_RATE = 16000            # Frecuencia de muestreo estándar\n",
        "output_filename = \"mis_audios_metrics\" # Nombre del archivo de salida\n",
        "\n",
        "def extract_features(audio_data, sample_rate, n_mfcc=40):\n",
        "    \"\"\"\n",
        "    Misma función de extracción para mantener compatibilidad.\n",
        "    \"\"\"\n",
        "    features = {}\n",
        "\n",
        "    # Asegurarse de que el audio sea flotante\n",
        "    if audio_data.dtype != np.float32:\n",
        "        audio_data = audio_data.astype(np.float32)\n",
        "\n",
        "    # MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=n_mfcc)\n",
        "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
        "    for i, mfcc_val in enumerate(mfccs_mean):\n",
        "        features[f'mfcc_{i+1}_mean'] = mfcc_val\n",
        "\n",
        "    # Chroma\n",
        "    chroma = librosa.feature.chroma_stft(y=audio_data, sr=sample_rate)\n",
        "    features['chroma_mean'] = np.mean(chroma)\n",
        "\n",
        "    # Mel Spectrogram\n",
        "    mel = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "    features['mel_mean'] = np.mean(mel)\n",
        "\n",
        "    # Contraste Espectral\n",
        "    contrast = librosa.feature.spectral_contrast(y=audio_data, sr=sample_rate)\n",
        "    features['contrast_mean'] = np.mean(contrast)\n",
        "\n",
        "    return features\n",
        "\n",
        "# --- SCRIPT PRINCIPAL ---\n",
        "\n",
        "processed_data = []\n",
        "\n",
        "if os.path.exists(local_folder):\n",
        "    print(f\"--- Buscando audios en la carpeta '{local_folder}' ---\")\n",
        "    local_files = [f for f in os.listdir(local_folder) if f.lower().endswith(('.wav', '.mp3', '.m4a', '.flac', '.ogg'))]\n",
        "\n",
        "    if local_files:\n",
        "        print(f\"Se encontraron {len(local_files)} archivos. Procesando...\")\n",
        "\n",
        "        for filename in tqdm(local_files):\n",
        "            file_path = os.path.join(local_folder, filename)\n",
        "            try:\n",
        "                # Cargar audio\n",
        "                audio_data, sample_rate = librosa.load(file_path, sr=SAMPLING_RATE)\n",
        "\n",
        "                # Extraer características\n",
        "                features = extract_features(audio_data, sample_rate)\n",
        "\n",
        "                # Etiqueta: Usamos '?' para que Orange sepa que debe predecirla\n",
        "                # O puedes poner el nombre del archivo para identificarlo luego\n",
        "                features['emotion'] = '?'\n",
        "                features['filename'] = filename # Añadimos el nombre para que sepas cuál es cual\n",
        "\n",
        "                processed_data.append(features)\n",
        "            except Exception as e:\n",
        "                print(f\"Error en {filename}: {e}\")\n",
        "    else:\n",
        "        print(f\"La carpeta '{local_folder}' está vacía.\")\n",
        "else:\n",
        "    print(f\"ERROR: No existe la carpeta '{local_folder}'. Créala y sube tus audios.\")\n",
        "\n",
        "# --- GUARDAR RESULTADOS ---\n",
        "if processed_data:\n",
        "    print(\"\\nGenerando archivos Excel y CSV...\")\n",
        "    df = pd.DataFrame(processed_data)\n",
        "\n",
        "    # Ordenar columnas: poner filename y emotion primero\n",
        "    cols = ['filename', 'emotion'] + [col for col in df.columns if col not in ['filename', 'emotion']]\n",
        "    df = df[cols]\n",
        "\n",
        "    # Guardar Excel\n",
        "    df.to_excel(f\"{output_filename}.xlsx\", index=False)\n",
        "    print(f\"¡Listo! Archivo guardado como: {output_filename}.xlsx\")\n",
        "\n",
        "    # Previsualización\n",
        "    print(df.head())\n",
        "else:\n",
        "    print(\"No se generó ningún archivo porque no hubo datos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArUQhU8T42Uo",
        "outputId": "e370f5d7-d5a1-4f2c-a35d-cf8834c0906d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Buscando audios en la carpeta '/content/drive/MyDrive/Practica_3_PH_Emociones/mis_audios' ---\n",
            "Se encontraron 4 archivos. Procesando...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4/4 [00:01<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generando archivos Excel y CSV...\n",
            "¡Listo! Archivo guardado como: mis_audios_metrics.xlsx\n",
            "              filename emotion  mfcc_1_mean  mfcc_2_mean  mfcc_3_mean  \\\n",
            "0  Frase_Felicidad.wav       ?  -391.139252   103.671509   -12.667977   \n",
            "1        Frase_Ira.wav       ?  -417.494873    89.615089   -15.923532   \n",
            "2    Frase_Neutral.wav       ?  -449.398254    80.846245    -5.330638   \n",
            "3   Frase_Tristeza.wav       ?  -443.144775   125.426842    -7.191640   \n",
            "\n",
            "   mfcc_4_mean  mfcc_5_mean  mfcc_6_mean  mfcc_7_mean  mfcc_8_mean  ...  \\\n",
            "0    41.431877    -1.082888    -1.081947    -4.123047    -4.281711  ...   \n",
            "1    47.248859    -3.212719     1.737698     0.765870    -3.559467  ...   \n",
            "2    32.807568    -0.146659     6.319160     1.672086    -7.004560  ...   \n",
            "3    49.907520     3.756506     6.658509     0.877906    -3.039200  ...   \n",
            "\n",
            "   mfcc_34_mean  mfcc_35_mean  mfcc_36_mean  mfcc_37_mean  mfcc_38_mean  \\\n",
            "0      4.206089      6.586481      6.938267      8.521297      8.401066   \n",
            "1     -0.333785     -1.632109      0.404660      0.155448      0.378953   \n",
            "2      0.497632      0.922300      1.470493     -0.201267     -0.741963   \n",
            "3     -0.675796     -2.284906     -0.866537     -1.427173     -1.768112   \n",
            "\n",
            "   mfcc_39_mean  mfcc_40_mean  chroma_mean  mel_mean  contrast_mean  \n",
            "0      8.190178      7.018180     0.447228  0.640147      18.881219  \n",
            "1      2.017339      1.882299     0.511679  0.320314      17.454838  \n",
            "2     -0.768425      0.349515     0.535111  0.365967      17.527560  \n",
            "3     -1.044011     -0.435079     0.466092  0.322929      18.364843  \n",
            "\n",
            "[4 rows x 45 columns]\n"
          ]
        }
      ]
    }
  ]
}